{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eac68f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft==0.2.0 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from peft==0.2.0) (1.19.5)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from peft==0.2.0) (6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from peft==0.2.0) (5.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from peft==0.2.0) (21.3)\n",
      "Requirement already satisfied: accelerate in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from peft==0.2.0) (0.17.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from peft==0.2.0) (2.0.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from peft==0.2.0) (4.27.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from packaging>=20.0->peft==0.2.0) (3.0.9)\n",
      "Requirement already satisfied: sympy in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft==0.2.0) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft==0.2.0) (2.8.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft==0.2.0) (3.7.4.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft==0.2.0) (3.6.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from torch>=1.13.0->peft==0.2.0) (2.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from transformers->peft==0.2.0) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from transformers->peft==0.2.0) (0.17.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from transformers->peft==0.2.0) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from transformers->peft==0.2.0) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from transformers->peft==0.2.0) (4.64.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers->peft==0.2.0) (2022.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers->peft==0.2.0) (0.4.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.13.0->peft==0.2.0) (2.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from requests->transformers->peft==0.2.0) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from requests->transformers->peft==0.2.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from requests->transformers->peft==0.2.0) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from requests->transformers->peft==0.2.0) (2.0.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from sympy->torch>=1.13.0->peft==0.2.0) (1.2.1)\n",
      "Requirement already satisfied: rouge-score in c:\\users\\khanh\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\khanh\\anaconda3\\lib\\site-packages (2.14.1)\n",
      "Requirement already satisfied: py7zr in c:\\users\\khanh\\anaconda3\\lib\\site-packages (0.20.6)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from rouge-score) (1.15.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from rouge-score) (1.19.5)\n",
      "Requirement already satisfied: nltk in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from rouge-score) (3.7)\n",
      "Requirement already satisfied: absl-py in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from rouge-score) (2.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from tensorboard) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from tensorboard) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from tensorboard) (2.23.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from tensorboard) (63.4.1)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from tensorboard) (1.59.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from tensorboard) (0.7.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from tensorboard) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: pyppmd<1.1.0,>=0.18.1 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from py7zr) (1.0.0)\n",
      "Requirement already satisfied: texttable in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from py7zr) (1.6.7)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from py7zr) (0.2.3)\n",
      "Requirement already satisfied: pycryptodomex>=3.6.6 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from py7zr) (3.19.0)\n",
      "Requirement already satisfied: inflate64>=0.3.1 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from py7zr) (0.3.1)\n",
      "Requirement already satisfied: pybcj>=0.6.0 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from py7zr) (1.0.1)\n",
      "Requirement already satisfied: brotli>=1.0.9 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from py7zr) (1.1.0)\n",
      "Requirement already satisfied: pyzstd>=0.14.4 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from py7zr) (0.15.9)\n",
      "Requirement already satisfied: psutil in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from py7zr) (5.9.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.4)\n",
      "Requirement already satisfied: click in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from nltk->rouge-score) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from nltk->rouge-score) (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from nltk->rouge-score) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from nltk->rouge-score) (2022.7.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from click->nltk->rouge-score) (0.4.5)\n"
     ]
    }
   ],
   "source": [
    "# install Hugging Face Libraries\n",
    "!pip install \"peft==0.2.0\"\n",
    "!pip install \"transformers==4.27.2\" \"datasets==2.9.0\" \"accelerate==0.17.1\" \"evaluate==0.4.0\" \"bitsandbytes==0.37.1\" loralib --upgrade --quiet\n",
    "# install additional dependencies needed for training\n",
    "!pip install rouge-score tensorboard py7zr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83a12a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration egalize--legal_summarization-454cda284ab7f119\n",
      "Found cached dataset csv (C:/Users/Khanh/.cache/huggingface/datasets/egalize___csv/egalize--legal_summarization-454cda284ab7f119/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186bab9a76dc44769356acd59a6cfd75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 356\n",
      "Test dataset size: 90\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset(\"egalize/legal_summarization\")\n",
    "\n",
    "print(f\"Train dataset size: {len(dataset['train'])}\")\n",
    "print(f\"Test dataset size: {len(dataset['test'])}\")\n",
    "\n",
    "# Train dataset size: 14732\n",
    "# Test dataset size: 819\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ad9d8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_id=\"nsi319/legal-pegasus\"\n",
    "\n",
    "# Load tokenizer of Legal-pegasus\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b707f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ef5c212885416c8dac2241ff0c01cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Khanh\\.cache\\huggingface\\datasets\\egalize___csv\\egalize--legal_summarization-454cda284ab7f119\\0.0.0\\6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317\\cache-5491b9397dda3d8b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source length: 152\n",
      "Max target length: 35\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "import numpy as np\n",
    "# The maximum total input sequence length after tokenization.\n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\n",
    "tokenized_inputs = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[\"original_text\"], truncation=True), batched=True, remove_columns=[\"original_text\", \"reference_summary\"])\n",
    "input_lengths = [len(x) for x in tokenized_inputs[\"input_ids\"]]\n",
    "# take 85 percentile of max length for better utilization\n",
    "max_source_length = int(np.percentile(input_lengths, 85))\n",
    "print(f\"Max source length: {max_source_length}\")\n",
    "\n",
    "# The maximum total sequence length for target text after tokenization.\n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\"\n",
    "tokenized_targets = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[\"reference_summary\"], truncation=True), batched=True, remove_columns=[\"original_text\", \"reference_summary\"])\n",
    "target_lengths = [len(x) for x in tokenized_targets[\"input_ids\"]]\n",
    "# take 90 percentile of max length for better utilization\n",
    "max_target_length = int(np.percentile(target_lengths, 90))\n",
    "print(f\"Max target length: {max_target_length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "340da70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb811010d85493bbe03136345162577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d1cd18010b4ecba3c1b34be5aca68a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys of tokenized dataset: ['input_ids', 'attention_mask', 'labels']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/356 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/90 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(sample,padding=\"max_length\"):\n",
    "    # add prefix to the input for t5\n",
    "    inputs = [\"summarize: \" + item for item in sample[\"original_text\"]]\n",
    "\n",
    "    # tokenize inputs\n",
    "    model_inputs = tokenizer(inputs, max_length=max_source_length, padding=padding, truncation=True)\n",
    "\n",
    "    # Tokenize targets with the `text_target` keyword argument\n",
    "    labels = tokenizer(text_target=sample[\"reference_summary\"], max_length=max_target_length, padding=padding, truncation=True)\n",
    "\n",
    "    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "    # padding in the loss.\n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=[\"original_text\", \"reference_summary\"])\n",
    "print(f\"Keys of tokenized dataset: {list(tokenized_dataset['train'].features)}\")\n",
    "\n",
    "# save datasets to disk for later easy loading\n",
    "tokenized_dataset[\"train\"].save_to_disk(\"data/train\")\n",
    "tokenized_dataset[\"test\"].save_to_disk(\"data/eval\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "289c741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to c:\\users\\khanh\\appdata\\local\\temp\\pip-req-build-nc0mtij2\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 63864e057fd4ecbf54c77599702873f7be871e65\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from transformers==4.34.0.dev0) (2022.7.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from transformers==4.34.0.dev0) (0.17.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from transformers==4.34.0.dev0) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from transformers==4.34.0.dev0) (21.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from transformers==4.34.0.dev0) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from transformers==4.34.0.dev0) (1.19.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from transformers==4.34.0.dev0) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from transformers==4.34.0.dev0) (2.28.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from transformers==4.34.0.dev0) (0.3.3)\n",
      "Collecting tokenizers<0.15,>=0.14\n",
      "  Downloading tokenizers-0.14.0-cp39-none-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 5.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0.dev0) (3.7.4.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.34.0.dev0) (2022.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers==4.34.0.dev0) (3.0.9)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "     -------------------------------------- 268.8/268.8 kB 8.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers==4.34.0.dev0) (0.4.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from requests->transformers==4.34.0.dev0) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from requests->transformers==4.34.0.dev0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from requests->transformers==4.34.0.dev0) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\khanh\\anaconda3\\lib\\site-packages (from requests->transformers==4.34.0.dev0) (2.0.4)\n",
      "Building wheels for collected packages: transformers\n",
      "  Building wheel for transformers (pyproject.toml): started\n",
      "  Building wheel for transformers (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for transformers: filename=transformers-4.34.0.dev0-py3-none-any.whl size=7746060 sha256=b71b49457f7400c1562fa5d90eb36a31505fecce94347da972ab3b2703efddab\n",
      "  Stored in directory: C:\\Users\\Khanh\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-sxmijhz4\\wheels\\f7\\92\\8c\\752ff3bfcd3439805d8bbf641614da38ef3226e127ebea86ee\n",
      "Successfully built transformers\n",
      "Installing collected packages: huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.17.1\n",
      "    Uninstalling huggingface-hub-0.17.1:\n",
      "      Successfully uninstalled huggingface-hub-0.17.1\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.13.3\n",
      "    Uninstalling tokenizers-0.13.3:\n",
      "      Successfully uninstalled tokenizers-0.13.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git 'C:\\Users\\Khanh\\AppData\\Local\\Temp\\pip-req-build-nc0mtij2'\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\Khanh\\\\anaconda3\\\\Lib\\\\site-packages\\\\~okenizers\\\\tokenizers.cp39-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6cbe9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "final_logits_bias doesn't have any device set.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18788\\1577612713.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoModelForSeq2SeqLM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_in_8bit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"shared\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoder\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"decoder\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lm_head\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m             return model_class.from_pretrained(\n\u001b[0m\u001b[0;32m    472\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   2645\u001b[0m                 \u001b[0moffload_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2646\u001b[0m                 \u001b[0merror_msgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2647\u001b[1;33m             \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2648\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2649\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[1;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, load_in_8bit, keep_in_fp32_modules)\u001b[0m\n\u001b[0;32m   2968\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2969\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlow_cpu_mem_usage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2970\u001b[1;33m                     new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(\n\u001b[0m\u001b[0;32m   2971\u001b[0m                         \u001b[0mmodel_to_load\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2972\u001b[0m                         \u001b[0mstate_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_meta_model\u001b[1;34m(model, state_dict, loaded_state_dict_keys, start_prefix, expected_keys, device_map, offload_folder, offload_index, state_dict_folder, state_dict_index, dtype, load_in_8bit, is_safetensors, keep_in_fp32_modules)\u001b[0m\n\u001b[0;32m    663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m                 \u001b[1;31m# TODO: group all errors and raise at the end.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 665\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{param_name} doesn't have any device set.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    666\u001b[0m             \u001b[0mparam_device\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparam_device\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"disk\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: final_logits_bias doesn't have any device set."
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, load_in_8bit=True, device_map = {\"shared\": 0, \"encoder\": 0, \"decoder\": 1, \"lm_head\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93c1d320",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target modules ['q', 'v'] not found in the base model. Please check the target modules and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18788\\3915484249.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_peft_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlora_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_trainable_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\peft\\mapping.py\u001b[0m in \u001b[0;36mget_peft_model\u001b[1;34m(model, peft_config)\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mpeft_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_prepare_prompt_learning_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeft_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mMODEL_TYPE_TO_PEFT_MODEL_MAPPING\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpeft_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_type\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\peft\\peft_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, peft_config)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpeft_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    643\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_model_prepare_inputs_for_generation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_inputs_for_generation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\peft\\peft_model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, peft_config)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_prompt_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLoraModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeft_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpeft_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"modules_to_save\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules_to_save\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpeft_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules_to_save\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\peft\\tuners\\lora.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config, model)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpeft_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_find_and_replace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[0mmark_only_lora_as_trainable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpeft_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\peft\\tuners\\lora.py\u001b[0m in \u001b[0;36m_find_and_replace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_replace_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_target_modules_in_base_model\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    182\u001b[0m                 \u001b[1;34mf\"Target modules {self.peft_config.target_modules} not found in the base model. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;34mf\"Please check the target modules and try again.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Target modules ['q', 'v'] not found in the base model. Please check the target modules and try again."
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training, TaskType\n",
    "\n",
    "\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70b61e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
